{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this, we will see how to dp sentiment analysis of text data using Deep Neural Networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "#from textblob import TextBlob, Word\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "%matplotlib inline\n",
    "from importlib import reload\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import tensorflow as tf\n",
    "tf.set_random_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the dataset (tweets.csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def converttoutf8(a):\n",
    "    return unicode(a, \"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('tweets.csv', engine = 'python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9093, 3)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>emotion_in_tweet_is_directed_at</th>\n",
       "      <th>is_there_an_emotion_directed_at_a_brand_or_product</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>.@wesley83 I have a 3G iPhone. After 3 hrs twe...</td>\n",
       "      <td>iPhone</td>\n",
       "      <td>Negative emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@jessedee Know about @fludapp ? Awesome iPad/i...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@swonderlin Can not wait for #iPad 2 also. The...</td>\n",
       "      <td>iPad</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@sxsw I hope this year's festival isn't as cra...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Negative emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@sxtxstate great stuff on Fri #SXSW: Marissa M...</td>\n",
       "      <td>Google</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          tweet_text  \\\n",
       "0  .@wesley83 I have a 3G iPhone. After 3 hrs twe...   \n",
       "1  @jessedee Know about @fludapp ? Awesome iPad/i...   \n",
       "2  @swonderlin Can not wait for #iPad 2 also. The...   \n",
       "3  @sxsw I hope this year's festival isn't as cra...   \n",
       "4  @sxtxstate great stuff on Fri #SXSW: Marissa M...   \n",
       "\n",
       "  emotion_in_tweet_is_directed_at  \\\n",
       "0                          iPhone   \n",
       "1              iPad or iPhone App   \n",
       "2                            iPad   \n",
       "3              iPad or iPhone App   \n",
       "4                          Google   \n",
       "\n",
       "  is_there_an_emotion_directed_at_a_brand_or_product  \n",
       "0                                   Negative emotion  \n",
       "1                                   Positive emotion  \n",
       "2                                   Positive emotion  \n",
       "3                                   Negative emotion  \n",
       "4                                   Positive emotion  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Consider only rows having Positive emotion and Negative emotion and remove other rows from the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1=data.copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = data1[~data1['is_there_an_emotion_directed_at_a_brand_or_product'].isin([\"No emotion toward brand or product\", \"I can't tell\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Negative emotion', 'Positive emotion'], dtype=object)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2.is_there_an_emotion_directed_at_a_brand_or_product.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Change the labels for Positive and Negative emotions as 1 and 0 respectively.\n",
    "\n",
    "Hint: use map on that column and give labels `or` You can use labelEncoder also."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "enc = LabelEncoder()\n",
    "data2['is_there_an_emotion_directed_at_a_brand_or_product'] = enc.fit_transform(data2['is_there_an_emotion_directed_at_a_brand_or_product'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>emotion_in_tweet_is_directed_at</th>\n",
       "      <th>is_there_an_emotion_directed_at_a_brand_or_product</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>.@wesley83 I have a 3G iPhone. After 3 hrs twe...</td>\n",
       "      <td>iPhone</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@jessedee Know about @fludapp ? Awesome iPad/i...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@swonderlin Can not wait for #iPad 2 also. The...</td>\n",
       "      <td>iPad</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@sxsw I hope this year's festival isn't as cra...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@sxtxstate great stuff on Fri #SXSW: Marissa M...</td>\n",
       "      <td>Google</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          tweet_text  \\\n",
       "0  .@wesley83 I have a 3G iPhone. After 3 hrs twe...   \n",
       "1  @jessedee Know about @fludapp ? Awesome iPad/i...   \n",
       "2  @swonderlin Can not wait for #iPad 2 also. The...   \n",
       "3  @sxsw I hope this year's festival isn't as cra...   \n",
       "4  @sxtxstate great stuff on Fri #SXSW: Marissa M...   \n",
       "\n",
       "  emotion_in_tweet_is_directed_at  \\\n",
       "0                          iPhone   \n",
       "1              iPad or iPhone App   \n",
       "2                            iPad   \n",
       "3              iPad or iPhone App   \n",
       "4                          Google   \n",
       "\n",
       "   is_there_an_emotion_directed_at_a_brand_or_product  \n",
       "0                                                  0   \n",
       "1                                                  1   \n",
       "2                                                  1   \n",
       "3                                                  0   \n",
       "4                                                  1   "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "text=data2[\"tweet_text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    .@wesley83 I have a 3G iPhone. After 3 hrs twe...\n",
       "1    @jessedee Know about @fludapp ? Awesome iPad/i...\n",
       "2    @swonderlin Can not wait for #iPad 2 also. The...\n",
       "3    @sxsw I hope this year's festival isn't as cra...\n",
       "4    @sxtxstate great stuff on Fri #SXSW: Marissa M...\n",
       "Name: tweet_text, dtype: object"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    1\n",
       "2    1\n",
       "3    0\n",
       "4    1\n",
       "Name: is_there_an_emotion_directed_at_a_brand_or_product, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "senti=data2['is_there_an_emotion_directed_at_a_brand_or_product']\n",
    "senti.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "### Convert Text Into numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tf.keras.preprocessing.text.Tokenizer(num_words=3000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Build Keras Tokenizer and fit on the text using `fit_on_texts` with no.of words=3000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.fit_on_texts(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6230"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer.word_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "#### Convert Text Into numbers using `texts_to_matrix` with `TF-IDF` mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = tokenizer.texts_to_matrix(text, mode='tfidf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3548, 3000)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Build the Graph\n",
    "\n",
    "#### Normalize the data using BatchNormalization layer, add fully connected layers with `200, 100, 60, 30, 1` neurons  with `relu` activations for hidden layers and `sigmoid` activation for the output layer. Use `binary_crossentropy` loss and `adam` optimizer for training the model. And, report the final validation accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize model, reshape & normalize data\n",
    "model = tf.keras.models.Sequential()\n",
    "\n",
    "#normalize data\n",
    "model.add(tf.keras.layers.BatchNormalization(input_shape=(3000,)))\n",
    "\n",
    "#Add Dense Layers\n",
    "model.add(tf.keras.layers.Dense(200, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(100, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(60, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(30, activation='relu'))\n",
    "#Output layer\n",
    "model.add(tf.keras.layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard = tf.keras.callbacks.TensorBoard(log_dir='/tmp/sentiment/dnn_v1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2838 samples, validate on 710 samples\n",
      "Epoch 1/30\n",
      "2838/2838 [==============================] - 1s 512us/step - loss: 0.0205 - acc: 0.9908 - val_loss: 1.4514 - val_acc: 0.8606\n",
      "Epoch 2/30\n",
      "2838/2838 [==============================] - 2s 533us/step - loss: 0.0210 - acc: 0.9922 - val_loss: 1.4209 - val_acc: 0.8634\n",
      "Epoch 3/30\n",
      "2838/2838 [==============================] - 2s 584us/step - loss: 0.0117 - acc: 0.9940 - val_loss: 1.6174 - val_acc: 0.8423\n",
      "Epoch 4/30\n",
      "2838/2838 [==============================] - 2s 561us/step - loss: 0.0155 - acc: 0.9937 - val_loss: 1.5771 - val_acc: 0.8479\n",
      "Epoch 5/30\n",
      "2838/2838 [==============================] - 2s 543us/step - loss: 0.0132 - acc: 0.9951 - val_loss: 1.5713 - val_acc: 0.8507\n",
      "Epoch 6/30\n",
      "2838/2838 [==============================] - 2s 599us/step - loss: 0.0078 - acc: 0.9965 - val_loss: 1.5115 - val_acc: 0.8746\n",
      "Epoch 7/30\n",
      "2838/2838 [==============================] - 1s 523us/step - loss: 0.0078 - acc: 0.9965 - val_loss: 1.6064 - val_acc: 0.8606\n",
      "Epoch 8/30\n",
      "2838/2838 [==============================] - 2s 568us/step - loss: 0.0069 - acc: 0.9961 - val_loss: 1.6287 - val_acc: 0.8592\n",
      "Epoch 9/30\n",
      "2838/2838 [==============================] - 1s 524us/step - loss: 0.0099 - acc: 0.9958 - val_loss: 1.5341 - val_acc: 0.8676\n",
      "Epoch 10/30\n",
      "2838/2838 [==============================] - 1s 517us/step - loss: 0.0095 - acc: 0.9954 - val_loss: 1.4504 - val_acc: 0.8845\n",
      "Epoch 11/30\n",
      "2838/2838 [==============================] - 2s 542us/step - loss: 0.0079 - acc: 0.9961 - val_loss: 1.5297 - val_acc: 0.8718\n",
      "Epoch 12/30\n",
      "2838/2838 [==============================] - 1s 513us/step - loss: 0.0189 - acc: 0.9944 - val_loss: 1.4445 - val_acc: 0.8592\n",
      "Epoch 13/30\n",
      "2838/2838 [==============================] - 2s 594us/step - loss: 0.0166 - acc: 0.9940 - val_loss: 1.5710 - val_acc: 0.8648\n",
      "Epoch 14/30\n",
      "2838/2838 [==============================] - 2s 585us/step - loss: 0.0130 - acc: 0.9937 - val_loss: 1.6239 - val_acc: 0.8746\n",
      "Epoch 15/30\n",
      "2838/2838 [==============================] - 2s 535us/step - loss: 0.0177 - acc: 0.9926 - val_loss: 1.4273 - val_acc: 0.8676\n",
      "Epoch 16/30\n",
      "2838/2838 [==============================] - 2s 599us/step - loss: 0.0165 - acc: 0.9940 - val_loss: 1.3897 - val_acc: 0.8817\n",
      "Epoch 17/30\n",
      "2838/2838 [==============================] - 2s 683us/step - loss: 0.0132 - acc: 0.9937 - val_loss: 1.3839 - val_acc: 0.8775\n",
      "Epoch 18/30\n",
      "2838/2838 [==============================] - 2s 636us/step - loss: 0.0127 - acc: 0.9944 - val_loss: 1.4536 - val_acc: 0.8789\n",
      "Epoch 19/30\n",
      "2838/2838 [==============================] - 2s 532us/step - loss: 0.0115 - acc: 0.9958 - val_loss: 1.4557 - val_acc: 0.8676\n",
      "Epoch 20/30\n",
      "2838/2838 [==============================] - 2s 534us/step - loss: 0.0073 - acc: 0.9972 - val_loss: 1.4542 - val_acc: 0.8789\n",
      "Epoch 21/30\n",
      "2838/2838 [==============================] - 1s 518us/step - loss: 0.0096 - acc: 0.9954 - val_loss: 1.4105 - val_acc: 0.8775\n",
      "Epoch 22/30\n",
      "2838/2838 [==============================] - 2s 543us/step - loss: 0.0073 - acc: 0.9965 - val_loss: 1.5469 - val_acc: 0.8746\n",
      "Epoch 23/30\n",
      "2838/2838 [==============================] - 2s 622us/step - loss: 0.0057 - acc: 0.9968 - val_loss: 1.6077 - val_acc: 0.8690\n",
      "Epoch 24/30\n",
      "2838/2838 [==============================] - 2s 647us/step - loss: 0.0068 - acc: 0.9965 - val_loss: 1.4465 - val_acc: 0.8803\n",
      "Epoch 25/30\n",
      "2838/2838 [==============================] - 2s 551us/step - loss: 0.0072 - acc: 0.9968 - val_loss: 1.5085 - val_acc: 0.8761\n",
      "Epoch 26/30\n",
      "2838/2838 [==============================] - 2s 604us/step - loss: 0.0104 - acc: 0.9954 - val_loss: 1.4273 - val_acc: 0.8732\n",
      "Epoch 27/30\n",
      "2838/2838 [==============================] - 2s 624us/step - loss: 0.0059 - acc: 0.9968 - val_loss: 1.4404 - val_acc: 0.8789\n",
      "Epoch 28/30\n",
      "2838/2838 [==============================] - 2s 646us/step - loss: 0.0068 - acc: 0.9965 - val_loss: 1.4386 - val_acc: 0.8859\n",
      "Epoch 29/30\n",
      "2838/2838 [==============================] - 2s 572us/step - loss: 0.0231 - acc: 0.9919 - val_loss: 1.2761 - val_acc: 0.8859\n",
      "Epoch 30/30\n",
      "2838/2838 [==============================] - 2s 542us/step - loss: 0.0119 - acc: 0.9954 - val_loss: 1.2922 - val_acc: 0.8845\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x26e0c828208>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Train the model\n",
    "model.fit(features,senti,          \n",
    "          validation_split=0.2,\n",
    "          callbacks=[tensorboard],\n",
    "          epochs=30,\n",
    "          batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3548/3548 [==============================] - 0s 76us/step\n",
      "Test accuracy: 0.9695603157379985\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(features, senti,batch_size=32, verbose=1)\n",
    "\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
